import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, 
    f1_score, matthews_corrcoef, roc_auc_score
)
import joblib
import os

# 合并训练集和测试集（确保路径正确，使用原始字符串避免转义）
df1 = pd.read_excel(r"D:/DATA/训练集.xlsx")
df2 = pd.read_excel(r"D:/DATA/测试集.xlsx")
df = pd.concat([df1, df2], ignore_index=True)  # 合并数据集

# 确保特征为numpy数组
X = df.iloc[:, 8:174].values  # 特征（第9列到第173列，转为numpy数组）
y = df.iloc[:, -1].astype(int).values  # 标签（转为整数numpy数组）

# 输出数据信息
print(f"合并后数据集形状: {df.shape}")
print(f"特征维度: {X.shape[1]}")
print(f"标签分布: {np.bincount(y)}\n")

# 定义十倍分层交叉验证
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# 预训练模型路径列表
model_paths = [
    r"D:/Model/dt_best_model.joblib",
    r"D:/Model/knn_best_model.joblib",
    r"D:/Model/mlp_best_model.joblib",
    r"D:/Model/SVM_best_model.joblib"
]

# 定义评估指标计算函数
def calculate_metrics(y_true, y_pred, y_score):
    # 处理二分类概率或决策分数
    if y_score.ndim == 1:  # 决策分数（如KNN的decision_function）
        y_pred_proba = np.column_stack([1 - y_score, y_score])
    else:  # 概率分数（如SVM的predict_proba）
        y_pred_proba = y_score
    
    return {
        'ACC': accuracy_score(y_true, y_pred),
        'Precision': precision_score(y_true, y_pred, zero_division=0),
        'Recall': recall_score(y_true, y_pred, zero_division=0),
        'F1': f1_score(y_true, y_pred, zero_division=0),
        'MCC': matthews_corrcoef(y_true, y_pred),
        'AUC': roc_auc_score(y_true, y_pred_proba[:, 1])  # 提取正类概率
    }

# 遍历模型进行交叉验证
for model_path in model_paths:
    try:
        model = joblib.load(model_path)
    except FileNotFoundError:
        print(f"错误：模型文件未找到 - {model_path}")
        continue
    
    model_name = os.path.basename(model_path).split('_')[0].upper()
    round_results = []
    all_metrics = []

    print(f"\n===== {model_name} 十倍交叉验证 =====")
    
    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]
        
        try:
            model.fit(X_train, y_train)
        except Exception as e:
            print(f"第{fold}轮训练失败: {e}")
            continue
        
        y_pred = model.predict(X_test)
        
        # 处理不同模型的预测分数
        if hasattr(model, 'predict_proba'):
            y_score = model.predict_proba(X_test)
        elif hasattr(model, 'decision_function'):
            y_score = model.decision_function(X_test)
        else:
            print(f"{model_name} 不支持概率或决策分数，跳过AUC计算")
            y_score = np.zeros((len(y_test), 2)) 
        
        try:
            metrics = calculate_metrics(y_test, y_pred, y_score)
        except Exception as e:
            print(f"第{fold}轮指标计算失败: {e}")
            continue
        
        all_metrics.append(metrics)
        round_results.append([fold] + list(metrics.values()))
        
        # 打印关键指标
        print(f"第{fold}轮: ACC={metrics['ACC']:.4f}, AUC={metrics['AUC']:.4f}")

    # 生成指标表格（跳过无有效数据的模型）
    if not all_metrics:
        print(f"{model_name} 所有轮次均失败，跳过表格生成")
        continue
    
    columns = ['轮次', 'ACC', 'Precision', 'Recall', 'F1', 'MCC', 'AUC']
    df_results = pd.DataFrame(round_results, columns=columns)
    
    # 格式化表格输出（保留4位小数）
    print("\n每轮评价指标表格:")
    print(df_results.to_string(index=False, float_format="{:.4f}".format))
    
    # 计算平均指标
    avg_metrics = {k: np.mean([m[k] for m in all_metrics]) for k in all_metrics[0]}
    std_metrics = {k: np.std([m[k] for m in all_metrics]) for k in all_metrics[0]}
    
    # 输出平均结果
    print("\n平均评价指标:")
    for metric, avg in avg_metrics.items():
        print(f"{metric}: {avg:.4f} ± {std_metrics[metric]:.4f}")
